{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import non_neg\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, UpSampling1D, UpSampling2D, UpSampling3D\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend\n",
    "from scipy import misc\n",
    "from keras.models import model_from_json\n",
    "from skimage.transform import resize\n",
    "\n",
    "##Modify Parameters Here\n",
    "bands=4\n",
    "hr_img_size=(450,450)\n",
    "inpt_lr_img_size=(135,135)\n",
    "sptlvarmeasure=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def array_from_tif_dir(tifdir,res):\n",
    "    finaldim=(len(os.listdir(os.getcwd() + '/tifs/' + tifdir)),res,res,4)\n",
    "    finalset=np.zeros(finaldim)\n",
    "    imgcounter=0\n",
    "    for imagename in os.listdir(os.getcwd() + '/tifs/' + tifdir):\n",
    "        image = misc.imread(os.getcwd() + '/tifs/' + tifdir + imagename)\n",
    "        finalset[imgcounter,:,:,:]= image\n",
    "        imgcounter+=1\n",
    "    return(finalset)\n",
    "y_train=array_from_tif_dir('HR/',hr_img_size[0])\n",
    "y_test=array_from_tif_dir('HRV/',hr_img_size[0])\n",
    "X_train=array_from_tif_dir('LR/',inpt_lr_img_size[0])\n",
    "X_test=array_from_tif_dir('LRV/',inpt_lr_img_size[0])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 4, 135, 135)\n",
      "(925, 4, 135, 135)\n",
      "(925, 4, 450, 450)\n",
      "(153, 4, 450, 450)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# newximglist=[]\n",
    "# newx2imglist=[]\n",
    "# imagecounter=0\n",
    "# # for image in X_train:\n",
    "# #     preimage=np.swapaxes(image.copy(),0,-1)\n",
    "# #     newximage=misc.imresize(preimage.copy(), inpt_lr_img_size)\n",
    "# #     finalimage=np.swapaxes(newximage.copy(),0,-1)\n",
    "# #     newximglist.append(finalimage.copy())\n",
    "# #     imagecounter+=1\n",
    "# # X_train=np.array(newximglist)\n",
    "# # for image in X_test:\n",
    "# #     preimage=np.swapaxes(image.copy(),0,-1)\n",
    "# #     newximage=misc.imresize(preimage.copy(), inpt_lr_img_size)\n",
    "# #     finalimage=np.swapaxes(newximage.copy(),0,-1)\n",
    "# #     newx2imglist.append(finalimage.copy())\n",
    "# #     imagecounter+=1\n",
    "# X_test=np.array(newx2imglist)\n",
    "y_train=np.swapaxes(y_train,1,-1)\n",
    "y_test=np.swapaxes(y_test,1,-1)\n",
    "X_train=np.swapaxes(X_train,1,-1)\n",
    "X_test=np.swapaxes(X_test,1,-1)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# 5. Preprocess input data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')[0:10] \n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')[0:10]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "y_train /= 255\n",
    "y_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    "ilis=inpt_lr_img_size[0]\n",
    "ihis=hr_img_size[0]\n",
    "ratio=float(ilis)/float(ihis)\n",
    "collapsesize=int((ratio**3)*ihis)\n",
    "solved=int((ilis-collapsesize+10)/8)\n",
    "\n",
    "model.add(Conv2D(filters=bands*3, kernel_size=(solved, solved), data_format='channels_first', activation='relu', input_shape=(bands,ilis,ilis)))\n",
    "model.add(Conv2D(filters=bands*3, kernel_size=(solved, solved), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(filters=bands*5, kernel_size=(solved, solved), data_format='channels_first', activation='relu'))\n",
    "model.add(Conv2D(filters=bands*5, kernel_size=(solved, solved), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=bands*7, kernel_size=(solved, solved), data_format='channels_first', activation='relu'))\n",
    "model.add(Conv2D(filters=bands*7, kernel_size=(solved, solved), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(filters=bands*12, kernel_size=(solved/2, solved/2), data_format='channels_first', activation='relu'))\n",
    "model.add(Conv2D(filters=bands*12, kernel_size=(solved/2, solved/2), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(filters=bands*15, kernel_size=(solved/2, solved/2), data_format='channels_first', activation='relu'))\n",
    "model.add(Conv2D(filters=bands*15, kernel_size=(solved/2, solved/2), data_format='channels_first', activation='relu'))\n",
    "currentsize=model.layers[-1].get_output_at(0).get_shape().as_list()[-1]\n",
    "reduceneed=currentsize-collapsesize\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Conv2D(filters=bands*15, kernel_size=(reduceneed+1, reduceneed+1), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "model.add(UpSampling2D((int(1/ratio*3),int(1/ratio*3)),data_format='channels_first'))\n",
    "print(int(1/ratio*3))\n",
    "model.add(Conv2D(filters=bands*15, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=bands*15, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(UpSampling2D((int(1/ratio),int(1/ratio)),data_format='channels_first'))\n",
    "print(int(1/ratio*2))\n",
    "model.add(Conv2D(filters=bands*12, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=bands*12, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(UpSampling2D((2,2),data_format='channels_first'))\n",
    "model.add(Conv2D(filters=bands*5, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=bands*5, kernel_size=(solved/2, solved/2), data_format='channels_first', kernel_constraint=non_neg(), activation='softmax'))\n",
    "currentsize=model.layers[-1].get_output_at(0).get_shape().as_list()[-1]\n",
    "bandcollapse=model.layers[-1].get_output_at(0).get_shape().as_list()[1]\n",
    "reduceneed=currentsize-hr_img_size[0]\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters=bands, kernel_size=(reduceneed+1, reduceneed+1), data_format='channels_first', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# 8. Compile model\n",
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 12, 120, 120)      12300     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 105, 105)      36876     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 105, 105)      420       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 90, 90)        61460     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 75, 75)        102420    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 75, 75)        300       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 75, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 60, 60)        143388    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 45, 45)        200732    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 45, 45)        180       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 45, 45)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 38, 38)        86064     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 31, 31)        147504    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 48, 31, 31)        124       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48, 31, 31)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 60, 24, 24)        184380    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 60, 17, 17)        230460    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 17, 17)        68        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60, 17, 17)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 60, 12, 12)        129660    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 12, 12)        48        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 60, 120, 120)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 60, 113, 113)      230460    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 60, 113, 113)      452       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 60, 106, 106)      230460    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60, 106, 106)      424       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 60, 318, 318)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 48, 311, 311)      184368    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 48, 311, 311)      1244      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 48, 304, 304)      147504    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 304, 304)      1216      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 48, 608, 608)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 20, 601, 601)      61460     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 20, 601, 601)      2404      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 20, 594, 594)      25620     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 20, 594, 594)      2376      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 450, 450)       1682004   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 450, 450)       1800      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 450, 450)       0         \n",
      "=================================================================\n",
      "Total params: 3,908,176\n",
      "Trainable params: 3,902,648\n",
      "Non-trainable params: 5,528\n",
      "_________________________________________________________________\n",
      "None\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16780543658257069948\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 182910976\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 16616148826810576425\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "(925, 4, 135, 135)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('model.json'):\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "opt = optimizers.Adam(lr=.05, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(X_train.shape)\n",
    "tensorboard = TensorBoard(log_dir=os.getcwd()+'/logs'.format(time.time()))\n",
    "writer = tf.summary.FileWriter(os.getcwd()+'/logs').add_graph(sess.graph)\n",
    "try:\n",
    "  loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "  loaded_model.fit(X_train, y_train, \n",
    "              batch_size=1, nb_epoch=1, verbose=1, callbacks=[tensorboard])\n",
    "  model=loaded_model\n",
    "except (NameError, ValueError) as e:\n",
    "    model.fit(X_train, y_train, \n",
    "              batch_size=1, nb_epoch=1, verbose=1, callbacks=[tensorboard])\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "class_scores= model.predict(X_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classes=[]\n",
    "for image in class_scores:\n",
    "    thisclass=image\n",
    "    classes.append(thisclass)\n",
    "f, ax = plt.subplots(10,3, figsize=(20, 16))\n",
    "axind0=0\n",
    "axind1=0\n",
    "imagecounter=0\n",
    "for image in X_test:\n",
    "    axind0=imagecounter\n",
    "    emptyximage=np.zeros((10,10,3))\n",
    "    emptyyimage=np.zeros((32,32,3))\n",
    "    emptytargetimage=np.zeros((32,32,3))\n",
    "    for band in range(1,4):\n",
    "        newximage=np.abs(image[band-1:band,0:10,0:10])\n",
    "        newtargetimage=y_test[imagecounter][band-1:band,0:32,0:32]\n",
    "        newyimage=np.abs(classes[imagecounter][band-1:band,0:32,0:32])\n",
    "        emptyximage[:,:,band-1:band]=newximage.reshape((10,10,1))*(1/np.max(newximage))\n",
    "        emptyyimage[:,:,band-1:band]=newyimage.reshape((32,32,1))*(1/np.max(newyimage))\n",
    "        emptytargetimage[:,:,band-1:band]=newtargetimage.reshape((32,32,1))*(1/np.max(newtargetimage))\n",
    "    imagecounter+=1\n",
    "    ax[axind0,0].imshow(emptyximage)\n",
    "    ax[axind0,1].imshow(emptyyimage)\n",
    "    ax[axind0,2].imshow(emptytargetimage)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
